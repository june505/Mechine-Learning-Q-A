## 1 SVM简述
### 算法描述
- **SVM**(*support vector mechine 支持向量机*)是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，它的学习策略是间隔最大化，求解得到分离超平面是唯一的，这也使得它有别于感知机。感知机利用误分类最小的策略，求得的分离超平面有无穷多个。
- 所谓**支持向量**是指那些在间隔区边缘的训练样本点。求解支持向量机就是：
1）寻找支持向量
2）最大化支持向量到分隔超平面的距离
可以把支持向量机的求解问题形式化为一个求解凸二次规划问题，也等价于正则化的**合页损失函数**。
- 根据数据是否线性可分可将支持向量机分为以下三种：
1）当训练数据线性可分时 — **硬间隔支持向量机**
2）当训练数据近似线性可分时 — **软间隔支持向量机**
3）当训练数据线性不可分时 — **非线性支持向量机**
- **核函数**表示将输入从输入空间映射到特征空间得到的特征向量之间的內积。通过使用核函数可以学习非线性支持向量机，等价于隐式地在高维的特征空间中学习线性支持向量机。
- 支持向量机的学习是在特征空间上学习的，因此输入都有输入空间转换到特征空间。

### 算法框架
1. 收集数据：可以使用任意方法
2. 准备数据：需要数值型数据
3. 分析数据：有助于可视化分隔超平面
4. 训练数据：SVM大部分的时间都源自训练，该过程主要实现两个参数的调优
5. 测试算法：十分简单地计算过程
6. 使用算法：训练好的参数就是我们所想得到的模型，可以应用于产品

### 算法思路：
（1）简单情况，线性可分情况，把问题转化为一个凸优化问题，可以用拉格朗日乘子法简化，然后用既有的算法解决
（2）复杂情况，线性不可分，用核函数将样本投射到高维空间，使其变成线性可分的情形，利用核函数来减少高纬度计算量

### 算法评价
- **优点**：泛化错误率低，计算开销不大，结果易解释
- **缺点**：对参数与核函数的选择敏感，原始分类器不加修改仅仅适用于二分类问题
- **适用数据类型**：数值型和标称型数据

### 线性可分SVM推导
- 推导目标函数
对于给定数据集
$T=\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}$,其中$x_i\epsilon \chi=R^n$,$y_i=\{+1,-1\}$,i=1,2,...,N. 
- 根据题设，分隔超平面
$$y(x)=w \cdot x+b=0$$
- 将数据代入分隔超平面：
$$
\begin{cases}
y(x_i)>0\Leftrightarrow&y_i>0\\
y(x_i)<0\Leftrightarrow&y_i<0
\end{cases} \Rightarrow \hat{\gamma_i}=y_i*y(x_i)>0
$$

- 当w,b等比例缩放时候，$\hat{\gamma}$也相应等比例缩放，因此对法向量w加以约束：
$$
{\hat{\gamma_i}\over||w||}={y_i*(w \cdot x_i+b)\over ||w||}
$$
